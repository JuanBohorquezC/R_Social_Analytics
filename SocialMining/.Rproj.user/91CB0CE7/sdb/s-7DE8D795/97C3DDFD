{
    "collab_server" : "",
    "contents" : "#########################################\n############## TWITTER #################\n#########################################\n\nsearchTermTwitter <- function(searchterm, posFile, negFile)\n{\n  since = as.Date(Sys.time()) - 7\n  since = as.character(format(since, '%Y-%m-%d'))\n  until = as.Date(Sys.time())\n  until = as.character(format(until, '%Y-%m-%d'))\n  \n  #access tweets and create cumulative file\n  list <- searchTwitter(searchterm, n = 1000, lang = 'es', retryOnRateLimit = 100, since=since, until=until)\n  df <- twListToDF(list)\n  df <- df[, order(names(df))]\n  df$created <- strftime(df$created, '%Y-%m-%d %H:%M')\n  \n  if (file.exists(paste(searchterm, '_stack_original.txt', sep = ''))==FALSE)\n    write.table(df, file=paste(searchterm, '_stack_original.txt', sep = ''), row.names=F, col.names = T, sep = \"\\t\")\n  \n  for(i in 1:length(df$text)){\n    \n    df[i,15] = gsub(\"\\n\", \" \", df[i,15])\n    df[i,15] = str_replace_all(df[i,15],\"[^[:graph:]]\", \" \")\n    df[i,15] = gsub('\\\"', \" \", df[i,15])\n    df[i,15] = gsub('https', \" \", df[i,15])\n    df[i,15] = gsub('bxogedf1jr', \" \", df[i,15])\n    df[i,15] = gsub('xfgsvge1dz', \" \", df[i,15])\n    \n  }\n  \n  if (file.exists(paste(searchterm, '_stack.txt', sep = ''))==FALSE)\n    write.table(df, file=paste(searchterm, '_stack.txt', sep = ''), row.names=F, col.names = T, sep = \"\\t\")\n  \n  #merge last access with cumulative file and remove duplicates\n  stack <- read.table(file=paste(searchterm, '_stack.txt', sep = ''), sep = \"\\t\", header = T, fill = T)\n  stack <- rbind(stack, df)\n  stack <- subset(stack, !duplicated(stack$text))\n  write.table(stack, file=paste(searchterm, '_stack.txt', sep = ''), row.names=F,  col.names = T, sep = \"\\t\")\n  \n  #evaluation tweets function\n  score.sentiment <- function(sentences, pos.words, neg.words, .progress='none')\n  {\n    require(plyr)\n    require(stringr)\n    \n    scores <- laply(sentences, function(sentence, pos.words, neg.words){\n      sentence <- gsub('[[:punct:]]', \"\", sentence)\n      sentence <- gsub('[[:cntrl:]]', \"\", sentence)\n      sentence <- tolower(sentence)\n      word.list <- str_split(sentence, ' ')\n      words <- unlist(word.list)\n      \n      pos.words <- tolower(as.character(pos.words[,1]))\n      neg.words <- tolower(as.character(neg.words[,1]))\n      \n      pos.matches <- match(words, pos.words)\n      neg.matches <- match(words, neg.words)\n      pos.matches <- !is.na(pos.matches)\n      neg.matches <- !is.na(neg.matches)\n      score <- sum(pos.matches) - sum(neg.matches)\n      return(score)\n    }, pos.words, neg.words, .progress=.progress)\n    scores.df <- data.frame(score=scores, text=sentences, date=stack$created, user=stack$screenName)\n    return(scores.df)\n  }\n  pos <- read.table(posFile, encoding = 'UTF-8') #folder with positive dictionary\n  neg <- read.table(negFile, encoding = 'UTF-8') #folder with negative dictionary\n  Dataset <- stack\n  Dataset$text <- as.factor(Dataset$text)\n  scores <- score.sentiment(Dataset$text, pos, neg, .progress='text')\n  write.table(scores, file=paste(searchterm, '_scores.txt', sep = ''), row.names=F, col.names = T, sep = '\\t') #save evaluation results into the file\n\n}\n\n#########################################\n############## FACEBOOK #################\n#########################################\n\nsearchInfacebook <- function(pageId, posFile, negFile)\n{\n  \n  since = as.Date(Sys.time()) - 7\n  since = as.character(format(since, '%Y/%m/%d'))\n  until = as.Date(Sys.time())\n  until = as.character(format(until, '%Y/%m/%d'))\n  \n  fb_page <- getPage(page=pageId, token=fb_oauth, n = 1000, since=since, until=until)\n  fb_page$created_time <- strftime(fb_page$created_time, '%Y-%m-%d %H:%M')\n  \n  if (file.exists(file='Ecopetrol_page_original.txt')==FALSE)\n    write.table(fb_page, file='Ecopetrol_page_original.txt', row.names=F, col.names = T, sep = \"\\t\")\n  \n  for(i in 1:length(fb_page$message)){\n    \n    fb_page$message = gsub(\"\\n\", \" \", fb_page$message)\n    fb_page$message = str_replace_all(fb_page$message,\"[^[:graph:]]\", \" \") \n    \n  }\n  \n  write.table(fb_page, file='Ecopetrol_page.txt', row.names=F,  col.names = T, sep = \"\\t\")\n  \n  ###Se lee la pagina de Ecopetrol con comentarios\n\n  post <- getPage(page=pageId, token = fb_oauth, n = 1000, feed = TRUE, reactions = TRUE, since=since, until=until)\n  post$created_time <- strftime(post$created_time, '%Y-%m-%d')\n  \n  if (file.exists('Ecopetrol_post_original.txt')==FALSE)\n    write.table(post, file='Ecopetrol_post_original.txt', row.names=F, col.names = T, sep = \"\\t\")\n  \n  for(i in 1:length(post$message)){\n    \n    post$message = gsub(\"\\n\", \" \", post$message)\n    post$message = str_replace_all(post$message,\"[^[:graph:]]\", \" \") \n    \n  }\n  \n  write.table(post, file='Ecopetrol_post.txt', row.names=F,  col.names = T, sep = \"\\t\")\n  \n  df.post.comments = NULL\n  df.post.post = NULL\n  df.post.likes = NULL\n  \n  for (i in 1:length(post$message)){\n    \n    if(is.na(post$id[i]) == FALSE){\n      comments = getPost(post=post$id[i], token = fb_oauth, comments = TRUE, likes = TRUE, n.comments = 1000, n.likes = 1000)\n      \n      if(length(which(names(comments) == \"comments\")) > 0){\n        if(dim(comments$comments)[1] > 0){\n          df.post.comments = rbind(df.post.comments, comments$comments)\n        }\n      }\n      if(length(which(names(comments) == \"post\")) > 0){\n        if(dim(comments$post)[1] > 0){\n          df.post.post = rbind(df.post.post, comments$post)\n        }\n      }\n      if(length(which(names(comments) == \"likes\")) > 0){\n        if(dim(comments$likes)[1] > 0){\n          df.post.likes = rbind(df.post.likes, comments$likes)\n        }\n      }\n    }\n  }\n  \n  \n  \n  write.table(df.post.comments, file='Ecopetrol_post_comments_original.txt', row.names=F,  col.names = T, sep = \"\\t\")\n  write.table(df.post.post, file='Ecopetrol_post_post_original.txt', row.names=F,  col.names = T, sep = \"\\t\")\n  write.table(df.post.likes, file='Ecopetrol_post_likes_original.txt', row.names=F,  col.names = T, sep = \"\\t\")\n  \n  df.post.comments$created_time <- strftime(df.post.comments$created_time, '%Y-%m-%d')\n  for(i in 1:length(df.post.comments$message)){\n    \n    df.post.comments$message = gsub(\"\\n\", \" \", df.post.comments$message)\n    df.post.comments$message = str_replace_all(df.post.comments$message,\"[^[:graph:]]\", \" \") \n    \n  }\n  \n  df.post.post$created_time <- strftime(df.post.post$created_time, '%Y-%m-%d')\n  for(i in 1:length(df.post.post$message)){\n    \n    df.post.post$message = gsub(\"\\n\", \" \", df.post.post$message)\n    df.post.post$message = str_replace_all(df.post.post$message,\"[^[:graph:]]\", \" \") \n    \n  }\n  \n  write.table(df.post.comments, file='Ecopetrol_post_comments.txt', row.names=F,  col.names = T, sep = \"\\t\")\n  write.table(df.post.post, file='Ecopetrol_post_post.txt', row.names=F,  col.names = T, sep = \"\\t\")\n  \n  score.sentiment <- function(sentences, pos.words, neg.words, .progress='none')\n  {\n    require(plyr)\n    require(stringr)\n    \n    scores <- laply(sentences, function(sentence, pos.words, neg.words){\n      \n      sentence <- gsub('[[:punct:]]', \"\", sentence)\n      sentence <- gsub('[[:cntrl:]]', \"\", sentence)\n      sentence <- tolower(sentence)\n      word.list <- str_split(sentence, ' ')\n      words <- unlist(word.list)\n      \n      pos.words <- tolower(as.character(pos.words[,1]))\n      neg.words <- tolower(as.character(neg.words[,1]))\n      \n      pos.matches <- match(words, pos.words)\n      neg.matches <- match(words, neg.words)\n      pos.matches <- !is.na(pos.matches)\n      neg.matches <- !is.na(neg.matches)\n      score <- sum(pos.matches) - sum(neg.matches)\n      return(score)\n    }, pos.words, neg.words, .progress=.progress)\n    scores.df <- data.frame(score=scores, text=sentences, date=df.post.comments$created_time, user=df.post.comments$from_name)\n    return(scores.df)\n  }\n  \n  pos <- read.table(posFile, encoding = 'UTF-8') #folder with positive dictionary\n  neg <- read.table(negFile, encoding = 'UTF-8') #folder with negative dictionaryDataset <- df.post.comments\n  Dataset <- df.post.comments\n  Dataset$text <- as.factor(df.post.comments$message)\n  scores <- score.sentiment(Dataset$text, pos, neg, .progress='text')\n  write.table(scores, file='Ecopetrol_score.txt', row.names=F, col.names = T, sep = '\\t') #save evaluation results into the file\n  \n}",
    "created" : 1496737540593.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3218226729",
    "id" : "97C3DDFD",
    "lastKnownWriteTime" : 1480375374,
    "last_content_update" : 1480375374,
    "path" : "C:/Data/R/SocialMining/data/SocialMining/Funciones.r",
    "project_path" : "Funciones.r",
    "properties" : {
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}